{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETOM_501A Final Project\n",
    "\n",
    "This final project will be part of the MSGT capstone project. The project accepts shapefiles or folders of shapefiles, runs them against a GIS model, and then generates a single output shapefile. This final project will perform these acts at a high level in order to prove the concept. In particular it will search for new files in a staging folder and process them against a simple data model, outputting a single file. The exact procedure is described in the code comments. A high-level description is available here: \n",
    "\n",
    "### Data Pipeline\n",
    "The data passes through multiple stages as it is processed. This is most easily described as three phases: \n",
    " - Data is ingested, placed in a named folder. That folder is placed in a stage folder\n",
    " - The names of each folder are checked against existing intermediary folders. If an intermediary folder exists, the new data must be an addition to that dataset, if no folder exists then the data is a new dataset. Add new data or create new dataset\n",
    " - For each modified or new dataset, process the new files\n",
    " - Remove the new files from the dataset. The end result of each dataset folder should be a single file\n",
    " - Merge all singular dataset files into a final, single file output\n",
    "\n",
    "The end result is: MANY input files --> SOME dataset files --> ONE output file\n",
    "\n",
    "### Project Fundamental Pseudocode\n",
    " - Scan a folder for files\n",
    " - If new files, check for the existence of a dataset \n",
    " - If existing dataset, add files to that dataset, flag dataset for processing\n",
    " - If no existing dataset, create new dataset, add files to dataset, flag dataset for processing, clear Stage folder\n",
    " - Process all flagged datasets, discard files as they are processed (end result should be one file per dataset)\n",
    " - Merge all datasets\n",
    " - Output single file, overwrite existing output\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new dataset: Datasets/Dataset88999 2.16.34 PM\n",
      "5 files copied to dataset: Dataset88999 2.16.34 PM\n",
      "Adding new dataset: Datasets/Dataset12345 2.16.34 PM\n",
      "5 files copied to dataset: Dataset12345 2.16.34 PM\n",
      "Adding new dataset: Datasets/DatasetExisting\n",
      "5 files copied to dataset: DatasetExisting\n",
      "Files processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "\n",
    "#Define paths to different folders\n",
    "stagePath = \"Stage/\"\n",
    "datasetPath = \"Datasets/\"\n",
    "outputPath = \"Output/\"\n",
    "\n",
    "#Checks for the existence of any files in a given path NOTE: Empty directoris within the path will return FALSE (Files only!)\n",
    "# IN: A path to check\n",
    "# OUT: True if files, False if no files\n",
    "def checkForNewFiles(path) : \n",
    "    return any(isfile(join(path, i)) for i in listdir(path))\n",
    "\n",
    "#Checks for the existence of any datasets with the given name\n",
    "#IN: (The name of the new dataset), (The path of the directory to check)\n",
    "#OUT: True if exists\n",
    "def checkForExistingDataset(name, path) :\n",
    "    for directory in os.listdir(path) :\n",
    "        if not directory.startswith('.') :\n",
    "            if directory == name :\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "#Moves a file from a source directory to a destination directory - Retains the filename\n",
    "#IN: (Source Directory), (Destination Directory), (Filename)\n",
    "#OUT: Nil\n",
    "def copyFile(source, dest, fileName) :\n",
    "    src = source+fileName\n",
    "    dst = dest+fileName\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "#Process Contents of Stage into Datasets - Takes staged folders, puts them in apropriate Dataset folders. Cleans Stage\n",
    "#IN: Nothing\n",
    "#OUT: Returns True if something happened\n",
    "def processStage() :\n",
    "    flag = False\n",
    "    if(checkForNewFiles(stagePath)) :\n",
    "        #For each new dataset: \n",
    "        for directory in os.listdir(stagePath) :\n",
    "            if not directory.startswith('.') :\n",
    "                flag = True\n",
    "                #If the dataset already exists add the new data to it: \n",
    "                if(checkForExistingDataset(directory, datasetPath)) :\n",
    "                    print(\"Existing Dataset Found: %s\" % (datasetPath+directory))\n",
    "                #Else it does not exist, so make a new dataset\n",
    "                else : \n",
    "                    pathlib.Path(datasetPath+directory).mkdir() \n",
    "                    print(\"Adding new dataset: %s\" % (datasetPath+directory))\n",
    "\n",
    "                #Now copy files to the datasets\n",
    "                files = os.listdir(stagePath+directory)\n",
    "                filesCopied = 0\n",
    "                for f in files :\n",
    "                    copyFile(stagePath+directory+\"/\", datasetPath+directory+\"/\", f)\n",
    "                    filesCopied += 1\n",
    "                print(\"%s files copied to dataset: %s\" % (filesCopied, directory))\n",
    "\n",
    "                #Finally, delete the Directory from Stage\n",
    "                shutil.rmtree(stagePath+directory)\n",
    "        if flag :\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#-----*********MAIN*********-----\n",
    "if(processStage()) :\n",
    "    print(\"Files processed\")\n",
    "\n",
    "    \n",
    "#Current Problem \n",
    "'''\n",
    "I have these intermediatry folders where some are updated and some are not. I need to flag which ones need processing \n",
    "so that I don't have to process all of my intermediary folders. \n",
    "\n",
    "How can I flag a folder for processing?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
